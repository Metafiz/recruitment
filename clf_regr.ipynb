{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn import ensemble\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "\n",
    "import re\n",
    "import string\n",
    "from tqdm.auto import tqdm, trange\n",
    "\n",
    "sns.set(); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_columns = ['custom_position', 'region_id', 'operating_schedule_id', 'offer_education_id', 'is_agency', \n",
    "                       'is_nonresident', 'is_male', 'driving_license', 'company_id', 'city_id']\n",
    "\n",
    "def change_columns_type(data):\n",
    "    # меняем тип некоторых колонок на категориальный\n",
    "    data['operating_schedule_id'] = data['operating_schedule_id'].astype('object')\n",
    "    data['is_male'] = data['is_male'].astype('object')\n",
    "    data['company_id'] = data['company_id'].astype('object')\n",
    "    data['is_agency'] = data['is_agency'].astype('object')\n",
    "    data['is_nonresident'] = data['is_nonresident'].astype('object')\n",
    "    data['offer_education_id'] = data['offer_education_id'].astype('object')\n",
    "    data['city_id'] = data['city_id'].astype('object')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Уменьшение вариативности названий вакансий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(text):\n",
    "    string.punctuation += '.'\n",
    "    return \"\".join([ch if ch not in string.punctuation else ' ' for ch in text])\n",
    "\n",
    "def remove_numbers(text):\n",
    "    return ''.join([i if not i.isdigit() else ' ' for i in text])\n",
    "\n",
    "def remove_multiple_spaces(text):\n",
    "\treturn re.sub(r'\\s+', ' ', text, flags=re.I)\n",
    "\n",
    "def remove_text_in_parentheses(text):\n",
    "    text = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", text)\n",
    "    return re.sub(\"[\\(\\[].*?[\\.\\]]\", \"\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproccess_custom_position_text(custom_position):\n",
    "    return remove_multiple_spaces(remove_numbers(remove_punctuation(remove_text_in_parentheses(custom_position)))).lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preproccess_custom_position(data):\n",
    "    print('Кол-во уникальных названий вакансий до обработки: ', data['custom_position'].nunique())\n",
    "    data['custom_position'] = data['custom_position'].apply(preproccess_custom_position_text)\n",
    "    print('Кол-во уникальных названий вакансий до обработки: ', data['custom_position'].nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Уменьшение кол-ва регионов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_seldom_regions(data):      \n",
    "    # находим регионы, которые встречаются в данных реже 10 раз\n",
    "    rvc_less_10 = data['region_id'].value_counts().loc[lambda x : x <= 10]\n",
    "    regions_less_10 = list(rvc_less_10.keys())\n",
    "    \n",
    "    # заменяем регионы, которые встречаются в данных реже 10 раз на регион \"Прочее\" (0)\n",
    "    data.loc[ data['region_id'].isin(regions_less_10), 'region_id'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Уменьшение кол-ва компаний"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_seldom_companies(data):      \n",
    "    # находим компании, которые встречаются в данных реже 10 раз\n",
    "    rvc_less_10 = data['company_id'].value_counts().loc[lambda x : x <= 10]\n",
    "    regions_less_10 = list(rvc_less_10.keys())\n",
    "    \n",
    "    # заменяем компании, которые встречаются в данных реже 10 раз на компанию \"Прочее\" (0)\n",
    "    data.loc[ data['company_id'].isin(regions_less_10), 'company_id'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Уменьшение кол-ва профессий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_seldom_target_prof(data):      \n",
    "    # находим компании, которые встречаются в данных реже 10 раз\n",
    "    tpvc_less_5 = data['target_prof'].value_counts().loc[lambda x : x <= 5]\n",
    "    prof_less_5 = list(tpvc_less_5.keys())\n",
    "    \n",
    "    # удаляем строки с профессиями, которые встречаются реже 5 раз\n",
    "    data.drop( data['target_prof'].isin(prof_less_5).index, inplace=True )    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Заполнение пропущенных значений"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_categorical_features(data):\n",
    "    # \"возраст от\" заменяем на моду (наиболее часто встречающееся значение)\n",
    "    data['age_from'].fillna(int(data['age_from'].mode()), axis=0, inplace=True)\n",
    "    \n",
    "    # \"возраст до\" заменяем на среднее значение\n",
    "    data['age_to'].fillna(data['age_to'].mean(axis=0), axis=0, inplace=True)\n",
    "    \n",
    "    data.loc[ data['offer_experience_year_count'] < 0, 'offer_experience_year_count'] = None\n",
    "    \n",
    "    # заменяем требуемый опыт на среднее значение\n",
    "    data['offer_experience_year_count'].fillna(data['offer_experience_year_count'].mean(axis=0), axis=0, inplace=True)\n",
    "    \n",
    "    data['company_id'].fillna(data['company_id'].describe().top, axis=0, inplace=True)\n",
    "    \n",
    "    data['driving_license'].fillna(data['driving_license'].describe().top, axis=0, inplace=True)\n",
    "    \n",
    "    # -100 - не указано\n",
    "    data['operating_schedule_id'].fillna(-100, axis=0, inplace=True)\n",
    "    \n",
    "    # 0 - любое\n",
    "    data['offer_education_id'].fillna(0, axis=0, inplace=True)\n",
    "    \n",
    "    # для пола заменяем константы True и False на 1 и 0\n",
    "    data.loc[ data['is_male'] == True, 'is_male'] = 1\n",
    "    data.loc[ data['is_male'] == False, 'is_male'] = 0\n",
    "    # для каиегориальной переменной is_male заменяем пропуски на новое значение - 2 (не указан)\n",
    "    data['is_male'].fillna(2, axis=0, inplace=True) \n",
    "    \n",
    "    # для is_agency заменяем константы True и False на 1 и 0\n",
    "    data.loc[ data['is_agency'] == True, 'is_agency'] = 1\n",
    "    data.loc[ data['is_agency'] == False, 'is_agency'] = 0\n",
    "    # для каиегориальной переменной is_agency заменяем пропуски на самое популярное значение\n",
    "    data['is_agency'].fillna(data['is_agency'].describe().top, axis=0, inplace=True)\n",
    "    \n",
    "    # для is_nonresident заменяем константы True и False на 1 и 0\n",
    "    data.loc[ data['is_nonresident'] == True, 'is_nonresident'] = 1\n",
    "    data.loc[ data['is_nonresident'] == False, 'is_nonresident'] = 0\n",
    "\n",
    "    # для каиегориальной переменной is_nonresident заменяем пропуски на самое популярное значение\n",
    "    data['is_nonresident'].fillna(data['is_nonresident'].describe().top, axis=0, inplace=True)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # заполнение пропущенных значений в разрезе по классам\n",
    "# def fill_categorical_features_by_target_prof(data):\n",
    "#     for prof in tqdm(data['target_prof'].unique()):\n",
    "#         prof_data = data.loc[ data['target_prof'] == prof ]\n",
    "#         fill_categorical_features(prof_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# возвращает бинарные и небинарные категориальные колонки\n",
    "def get_binary_nonbinary_columns(data):\n",
    "    change_columns_type(data)\n",
    "    data_describe = data.describe(include=[object])\n",
    "    \n",
    "    binary_columns    = [c for c in categorical_columns if data_describe[c]['unique'] == 2]\n",
    "    nonbinary_columns = [c for c in categorical_columns if data_describe[c]['unique'] > 2]\n",
    "    print('Бинарные категориальные признаки: ', binary_columns)\n",
    "    print('Небинарные категориальные признаки: ', nonbinary_columns)\n",
    "    \n",
    "    return (binary_columns, nonbinary_columns)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Нормализация числовых данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_columns = ['age_from', 'age_to', 'offer_experience_year_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_numerical_columns(data):\n",
    "    # выделяем датафрейм с числовыми признаками и нормируем значения\n",
    "    data_numerical = data[numerical_columns]\n",
    "    scaler = preprocessing.StandardScaler().fit(data_numerical)\n",
    "    data_numerical = scaler.transform(data_numerical)\n",
    "    return pd.DataFrame(data_numerical, columns=numerical_columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Векторизация небинарных категориальных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dummy_columns(data, nonbinary_columns):\n",
    "    # для небинарных признаков создаём фиктивные колонки\n",
    "    data_nonbinary = pd.get_dummies(data[nonbinary_columns])\n",
    "    return data_nonbinary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Объединение всех признаков в один дата-фрейм"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_columns(data_numerical, data_binary, data_nonbinary):\n",
    "    data_all = pd.concat((data_numerical, data_binary, data_nonbinary), axis=1)\n",
    "    data_all = pd.DataFrame(data_all, dtype=float)\n",
    "    print('Размер матрицы всех признаков: ', data_all.shape)\n",
    "    return data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_prof(data):\n",
    "    # выделяем отдельный вектор-столбец с целевой переменной - target_prof\n",
    "    y = data['target_prof']\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_target_salaries(data):\n",
    "    # целевые столбцы для предсказания зарплат\n",
    "    y_sf = data['salary_from']\n",
    "    y_st = data['salary_to']\n",
    "    return (y_sf, y_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('rabotaru_ru/data/train_public.csv')\n",
    "#data_test = pd.read_csv('rabotaru_ru/data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во уникальных названий вакансий до обработки:  14345\n",
      "Кол-во уникальных названий вакансий до обработки:  10641\n",
      "Бинарные категориальные признаки:  ['is_agency', 'is_nonresident']\n",
      "Небинарные категориальные признаки:  ['custom_position', 'region_id', 'operating_schedule_id', 'offer_education_id', 'is_male', 'driving_license', 'company_id', 'city_id']\n",
      "Размер матрицы всех признаков:  (56297, 11506)\n",
      "Wall time: 4.53 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "change_columns_type(data)\n",
    "preproccess_custom_position(data)\n",
    "#delete_seldom_target_prof(data) # !!!\n",
    "replace_seldom_regions(data)\n",
    "replace_seldom_companies(data)\n",
    "fill_categorical_features(data) \n",
    "binary_columns, nonbinary_columns = get_binary_nonbinary_columns(data)\n",
    "data_numerical = normalize_numerical_columns(data)\n",
    "data_nonbinary = create_dummy_columns(data, nonbinary_columns)\n",
    "data_all = concat_columns(data_numerical, data[binary_columns], data_nonbinary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_all.to_csv('data_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Балансировка классов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = ensemble.RandomForestClassifier(n_estimators=100, random_state=11)\n",
    "#over = SMOTE()\n",
    "over = RandomOverSampler(random_state=0)\n",
    "under = RandomUnderSampler(sampling_strategy=0.5)\n",
    "steps = [('over', over)] # , ('under', under) , ('model', rf)\n",
    "pipeline = Pipeline(steps=steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data_all\n",
    "y = get_target_prof(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 429. MiB for an array with shape (4882, 11506) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\pipeline.py\u001b[0m in \u001b[0;36mfit_resample\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    345\u001b[0m             \u001b[0mfit_params_last_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfit_params_steps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    346\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlast_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"fit_resample\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 347\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mlast_step\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0myt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params_last_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    348\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0mif_delegate_has_method\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdelegate\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"_final_estimator\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     81\u001b[0m         )\n\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 83\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     84\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m         y_ = (\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\imblearn\\over_sampling\\_random_over_sampler.py\u001b[0m in \u001b[0;36m_fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    229\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m                 \u001b[1;31m# generate a bootstrap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m                 \u001b[0mX_resampled\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_safe_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbootstrap_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m             \u001b[0my_resampled\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_safe_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbootstrap_indices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m_safe_indexing\u001b[1;34m(X, indices, axis)\u001b[0m\n\u001b[0;32m    375\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_pandas_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    376\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"shape\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 377\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_array_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    378\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    379\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0m_list_indexing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m_array_indexing\u001b[1;34m(array, key, key_dtype, axis)\u001b[0m\n\u001b[0;32m    199\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 201\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    202\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 429. MiB for an array with shape (4882, 11506) and data type float64"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "X, y = pipeline.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение и валидация модели для проверки её качества"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Разделение выборок для классификации\n",
    "X = data_all\n",
    "y = get_target_prof(data)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.1, random_state = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 5min 11s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(random_state=11)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "rf = ensemble.RandomForestClassifier(n_estimators=100, random_state=11)\n",
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2.07 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "y_test_predict = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7539964476021315 0.5119519772100021\n"
     ]
    }
   ],
   "source": [
    "acc = accuracy_score(y_test, y_test_predict)\n",
    "f1 = f1_score(y_test, y_test_predict, average = 'macro')\n",
    "print(acc, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf = GradientBoostingClassifier(n_estimators=100, random_state=11)\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Обучение модели на всех данных и прогнозирование на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X = data_all\n",
    "y = get_target_prof(data)\n",
    "\n",
    "from sklearn import ensemble\n",
    "rf = ensemble.RandomForestClassifier(n_estimators=100, random_state=11)\n",
    "rf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('rabotaru_ru/data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во уникальных названий вакансий до обработки:  5130\n",
      "Кол-во уникальных названий вакансий до обработки:  4273\n",
      "Бинарные категориальные признаки:  ['is_agency', 'is_nonresident']\n",
      "Небинарные категориальные признаки:  ['custom_position', 'region_id', 'operating_schedule_id', 'offer_education_id', 'is_male', 'driving_license', 'company_id', 'city_id']\n",
      "Размер матрицы всех признаков:  (14074, 8749)\n",
      "Wall time: 954 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "change_columns_type(data)\n",
    "preproccess_custom_position(data)\n",
    "binary_columns, nonbinary_columns = fill_categorical_features(data)\n",
    "data_numerical = normalize_numerical_columns(data)\n",
    "data_nonbinary = create_dummy_columns(data, nonbinary_columns)\n",
    "data_all = concat_columns(data_numerical, data[binary_columns], data_nonbinary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Кол-во отсутствующих в тестовой выборке колонок:  17391\n",
      "Wall time: 1min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# дополняем матрицу тестовой выборки колонками из обучающей для возможности использования обученной модели\n",
    "missing_cols = set( X.columns ) - set( X_test.columns )\n",
    "print('Кол-во отсутствующих в тестовой выборке колонок: ', len(list(missing_cols)))\n",
    "\n",
    "for c in missing_cols:\n",
    "    X_test[c] = 0\n",
    "X_test = X_test[X.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "y_test = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['водитель', 'упаковщик', 'врач', 'повар', 'заправщик', 'почтальон',\n",
       "       'рабочий', 'аналитик', 'сварщик', 'столяр'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>salary_from</th>\n",
       "      <th>salary_to</th>\n",
       "      <th>target_prof</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>286961</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>водитель</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>423834</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>упаковщик</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>336464</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>врач</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>287634</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>повар</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>174883</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>заправщик</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14069</th>\n",
       "      <td>290923</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>упаковщик</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14070</th>\n",
       "      <td>175080</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>упаковщик</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14071</th>\n",
       "      <td>451820</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>менеджер</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14072</th>\n",
       "      <td>257668</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>помощник</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14073</th>\n",
       "      <td>213393</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>мастер</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14074 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id  salary_from  salary_to target_prof\n",
       "0      286961            0          0    водитель\n",
       "1      423834            0          0   упаковщик\n",
       "2      336464            0          0        врач\n",
       "3      287634            0          0       повар\n",
       "4      174883            0          0   заправщик\n",
       "...       ...          ...        ...         ...\n",
       "14069  290923            0          0   упаковщик\n",
       "14070  175080            0          0   упаковщик\n",
       "14071  451820            0          0    менеджер\n",
       "14072  257668            0          0    помощник\n",
       "14073  213393            0          0      мастер\n",
       "\n",
       "[14074 rows x 4 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# формируем итоговый дата-фрейм с прогнозом\n",
    "res_columns = ['id','salary_from','salary_to','target_prof']\n",
    "zero_list =  [0] * len(data['id']) # data['id']\n",
    "\n",
    "df_res = pd.DataFrame(list(zip(data['id'], zero_list, zero_list, y_test)), \n",
    "                      columns=res_columns)\n",
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 20.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_res.to_csv('submit_c.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
